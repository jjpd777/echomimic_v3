python infer_flash_pro.py --GPU_memory_mode "sequential_cpu_offload" \
    --image_path "/workspace/echomimic_v3/sample.png" \
    --audio_path "/workspace/echomimic_v3/sample.wav" \
    --prompt "A person is speaking." \
    --num_inference_steps 8 \
    --config_path "/workspace/echomimic_v3/config/config.yaml" \
    --model_name "/workspace/echomimic_v3/flash-pro/Wan2.1-Fun-V1.1-1.3B-InP" \
    --transformer_path "/workspace/echomimic_v3/flash-pro/transformer/diffusion_pytorch_model.safetensors" \
    --wav2vec_model_dir "/workspace/echomimic_v3/flash-pro/chinese-wav2vec2-base" \
    --save_path "outputs" \
    --sampler_name "Flow_Unipc" \
    --video_length 81 \
    --guidance_scale 6.0 \
    --audio_guidance_scale 3.0 \
    --seed 43 \
    --enable_teacache \
    --weight_dtype "bfloat16" \
    --sample_size 768 768 \
    --fps 25
